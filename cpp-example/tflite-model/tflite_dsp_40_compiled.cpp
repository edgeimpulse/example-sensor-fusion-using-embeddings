/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 26.10.2023 18:23:45

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#elif defined __ICCARM__
#define ALIGN(x) __attribute__((aligned(x)))
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#ifndef CONFIG_IDF_TARGET_ESP32S3
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#else
#define EI_MAX_SCRATCH_BUFFER_COUNT 8
#endif // CONFIG_IDF_TARGET_ESP32S3
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 16016;
#else
constexpr int kTensorArenaSize = 14992;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[9];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,6450 } };
const TfArray<1, float> quant0_scale = { 1, { 0.0033511521760374308, } };
const TfArray<1, int> quant0_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 50, 129, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 50, 1, 8, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 25, 8, };
const TfArray<1, int> tensor_dimension3 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data4[2] = { -1, 208, };
const TfArray<1, int> tensor_dimension4 = { 1, { 2 } };
const ALIGN(16) int32_t tensor_data5[4] = { 1, 25, 1, 16, };
const TfArray<1, int> tensor_dimension5 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data6[16] = { 100, -8460, -32, 24875, 17574, 22, 18037, -5762, -1000, -2427, 19658, -9024, -5335, -22, -7460, -3820, };
const TfArray<1, int> tensor_dimension6 = { 1, { 16 } };
const TfArray<16, float> quant6_scale = { 16, { 3.35056429321412e-05, 3.425125396461226e-05, 3.1417621357832104e-05, 1.8867311155190691e-05, 2.7676283934852108e-05, 3.6795776395592839e-05, 2.6461977540748194e-05, 3.1505391234531999e-05, 2.6617872208589688e-05, 1.9936585886171088e-05, 2.5178467694786377e-05, 3.1907875381875783e-05, 2.9522963814088143e-05, 4.5554323151009157e-05, 4.3256553908577189e-05, 5.0867860409198329e-05, } };
const TfArray<16, int> quant6_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int8_t tensor_data7[16*1*3*8] = { 
  /* [0][0][][] */ 32,68,80,60,-42,-16,2,39, -3,31,-10,-30,-54,9,85,-91, 22,127,12,32,-90,-58,61,5, 
  /* [1][0][][] */ -44,127,-8,75,0,-89,-15,30, -57,-29,-53,5,60,84,64,83, 86,70,18,-91,-61,-74,-2,-11, 
  /* [2][0][][] */ -4,95,-28,11,10,-27,22,63, 114,36,88,71,64,-78,11,114, -64,127,62,-50,-19,20,81,10, 
  /* [3][0][][] */ 127,-36,97,-84,119,-24,-125,113, 70,-37,-16,111,-7,-110,-98,73, -96,-36,-51,-81,65,-24,106,102, 
  /* [4][0][][] */ -62,-43,-95,-75,-127,-109,13,30, -103,-41,-64,-87,-24,59,44,-38, 41,4,68,-76,-112,99,-39,12, 
  /* [5][0][][] */ -68,69,39,66,-25,-80,-51,80, -78,44,-39,-36,59,60,-67,-37, -51,127,55,57,4,3,-61,47, 
  /* [6][0][][] */ 84,-25,32,60,-102,-42,35,11, 56,-24,81,-127,-34,-22,41,61, -65,-23,-92,67,-37,11,-95,-106, 
  /* [7][0][][] */ -26,66,-13,-127,-98,94,81,34, 52,107,68,79,69,68,39,50, -3,-31,-78,-34,104,23,98,20, 
  /* [8][0][][] */ 69,-95,95,106,15,-19,99,82, -45,-66,-81,98,91,-21,-127,126, -19,-52,101,89,34,77,-34,-32, 
  /* [9][0][][] */ 68,-89,60,111,-44,95,113,73, -37,-55,-45,-122,32,68,-66,43, 6,-76,-51,120,-45,57,-62,127, 
  /* [10][0][][] */ -79,-27,-70,24,35,-73,72,-37, -123,-28,-44,-34,-55,-127,-93,25, -52,-27,-68,48,-73,46,-38,114, 
  /* [11][0][][] */ -101,127,-49,77,60,27,-54,-82, -28,-28,42,-2,87,-113,-6,26, -48,-8,-72,71,-98,-83,-79,-19, 
  /* [12][0][][] */ -87,68,-72,127,-48,1,81,-8, 66,-19,-84,-27,-91,76,-95,-26, 79,117,84,44,53,-95,-72,70, 
  /* [13][0][][] */ 19,58,-14,-24,-72,55,-38,-25, 49,127,-27,0,-65,-54,-39,-49, -26,93,58,1,62,-51,-43,51, 
  /* [14][0][][] */ 30,14,46,-35,-21,33,13,-56, -16,127,59,4,-8,-12,42,-61, 54,-53,2,64,11,-75,2,-72, 
  /* [15][0][][] */ 40,95,-6,-39,-1,-34,-37,31, -10,-9,28,-26,0,-47,-1,16, -48,-127,34,-50,-57,-16,14,20, 
};
const TfArray<4, int> tensor_dimension7 = { 4, { 16,1,3,8 } };
const TfArray<16, float> quant7_scale = { 16, { 0.0028497935272753239, 0.002913210541009903, 0.00267219846136868, 0.0016047427197918296, 0.0023539823014289141, 0.0031296329107135534, 0.0022507004905492067, 0.002679663710296154, 0.002263959962874651, 0.0016956890467554331, 0.0021415327209979296, 0.0027138967998325825, 0.0025110500864684582, 0.0038745834026485682, 0.0036791486199945211, 0.004326521884649992, } };
const TfArray<16, int> quant7_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int32_t tensor_data8[8] = { -123, -30358, -9437, -9482, -9012, -8026, -7733, -9686, };
const TfArray<1, int> tensor_dimension8 = { 1, { 8 } };
const TfArray<8, float> quant8_scale = { 8, { 4.0250033634947613e-06, 7.8259117799461819e-06, 3.9754941099090502e-06, 4.2906281123578083e-06, 4.4083258217142429e-06, 4.013112629763782e-06, 3.8808097997389268e-06, 4.0047762013273314e-06, } };
const TfArray<8, int> quant8_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int8_t tensor_data9[8*1*3*129] = { 
  /* [0][0][][] */ -29,29,-24,-8,-124,-50,33,-65,-88,-56,2,-112,57,-100,-100,14,-34,-56,-49,-126,5,-33,14,47,36,-26,-15,-110,-8,-119,-102,43,-3,-70,39,-36,2,-49,30,50,1,17,-92,52,-45,-60,85,33,-31,-38,76,82,-97,77,47,75,78,22,-30,50,-105,35,26,-9,-46,-63,59,-43,50,-63,-93,67,-85,-96,-54,8,40,20,-77,9,43,-31,64,-85,74,-120,-107,-47,-63,45,-88,-114,1,-119,-94,-38,-95,-74,29,-91,15,-79,-19,3,-1,-104,-105,2,-52,-75,-104,-102,-25,-88,-67,-61,-50,66,45,40,-80,-79,-23,53,73,-43,-108,-9,55, -123,14,72,-45,-50,-4,-105,26,-41,72,-122,69,-13,-40,53,6,74,-35,43,44,21,15,51,-80,-101,-93,-16,58,-84,64,38,-42,-20,-96,31,9,-14,73,-22,86,26,68,48,-13,-35,56,11,-56,-106,1,-72,-82,6,-63,22,54,-28,-43,61,33,-111,54,-86,-62,-42,60,-30,-74,-76,-55,-102,1,-67,-4,-119,26,-33,-95,-124,-97,36,-45,55,-35,-86,59,-127,-31,-12,-89,-85,-92,38,65,-53,46,8,-30,-2,-12,73,-65,-107,76,51,1,-25,61,0,-12,-106,78,77,-6,-46,-6,-87,31,74,-92,-36,-21,-85,-29,-105,32,4,-62,-35, -59,6,-53,-17,62,-77,-107,-62,-51,22,-50,53,-81,4,-29,4,-12,52,-72,25,-33,-59,-25,-11,42,-30,-76,-74,52,-117,-36,-12,-69,22,-52,-91,-53,-120,61,-78,-38,26,20,56,27,-40,-22,11,-18,-71,-24,-77,-122,39,80,-7,30,47,-7,-24,-100,29,63,-116,65,26,70,-110,-115,-36,-46,39,78,-114,-32,-44,-33,55,-95,-98,-52,62,-28,-103,40,25,-34,-49,-5,67,55,75,21,54,55,-15,-8,-97,37,28,-17,-53,-67,-107,-79,-126,-56,-49,16,67,-11,53,-88,-119,-30,-113,-116,-73,58,-85,20,-88,-43,-71,43,-92,13,11,-65, 
  /* [1][0][][] */ -127,-91,-52,-30,-127,-27,-112,-21,-69,-63,-63,-74,-11,-87,12,-7,-58,-35,24,23,18,-18,24,30,35,-23,-41,-9,-22,10,16,-40,-10,36,20,35,-26,-26,5,-24,47,1,-18,24,1,64,52,61,28,26,32,31,86,-6,-5,92,60,14,30,40,53,86,9,8,-29,7,11,-12,10,60,0,15,2,50,12,-5,-36,-12,-3,-61,44,-39,-1,-42,-44,43,47,9,-51,15,-26,32,35,-30,-8,7,6,31,32,-16,-16,6,-40,27,23,54,-12,70,8,-10,38,0,51,-19,5,72,51,15,-14,44,15,61,-19,28,33,-38,17,-31,2, -32,-30,-80,-10,-82,-85,-67,-94,-50,-28,-68,-94,-19,-4,-28,32,33,-48,-24,-12,-14,7,-33,35,-20,0,3,-18,33,-34,-26,-2,12,9,7,38,40,-38,15,50,57,36,-23,29,36,61,63,-18,67,30,43,79,102,88,8,28,58,37,77,22,6,14,73,-28,23,3,19,-31,61,19,-22,20,48,-30,33,27,-36,-60,-51,38,-27,31,-32,29,-49,8,8,-25,-14,18,64,25,28,29,7,-41,33,58,13,20,23,60,-6,-32,48,42,35,16,51,37,-11,12,23,39,52,99,48,-10,78,57,0,41,69,53,29,66,7,-33,12, -105,-76,-64,-56,-96,-54,-38,-21,-101,-81,-73,-42,-45,-14,-7,27,26,-14,14,-45,12,-23,58,0,72,53,42,13,57,-21,29,34,20,60,52,-34,-21,-29,49,-7,-18,-43,20,54,-19,49,10,6,5,71,55,37,86,24,52,96,57,43,98,91,35,83,6,7,89,-9,60,10,1,37,30,-14,45,-14,-20,-16,-18,32,-27,-1,33,-44,-24,49,64,-25,0,17,27,24,60,58,-27,53,-42,11,16,-1,29,-27,-14,-36,26,24,38,-8,65,54,71,46,77,9,24,-19,64,18,74,-5,-32,44,41,-13,-5,-21,-42,-45,-44,-19,31, 
  /* [2][0][][] */ 38,69,-113,-57,-113,-113,18,26,-82,-7,18,-105,23,-125,-86,36,33,-91,46,8,70,-32,-29,-17,8,-101,-102,-119,-33,-126,-99,1,-112,33,71,-84,22,-101,-41,-65,7,-27,-20,-77,-13,-25,9,-82,52,-105,75,-112,-76,-6,72,30,-119,-81,39,47,-13,58,-69,-35,-86,71,-74,-29,-109,-109,-78,46,-116,1,-54,-76,-122,21,-119,-81,26,-105,-90,-38,37,-44,76,75,33,-92,-112,-54,3,16,-3,33,-104,-103,75,-119,26,13,-99,-4,57,-119,-20,-86,-21,40,11,-58,-23,-112,36,-77,-18,76,-80,-91,10,34,-105,-46,-68,26,-57,-20,58, 18,-44,-46,19,35,-45,25,45,38,-37,-93,-15,-91,-91,57,-52,-15,-2,-52,-62,-84,67,1,-57,-15,17,-41,40,-92,-86,66,-52,0,24,1,65,-4,-116,62,38,37,-56,20,-20,-80,27,-31,53,37,64,-88,-18,-49,51,21,-67,-43,-26,-120,35,23,-110,2,65,54,0,-75,20,-55,-69,-17,16,-68,3,36,-15,10,5,62,4,-73,-17,-69,23,-54,-106,-50,-61,60,0,-18,-105,-64,-31,-69,-6,-96,-28,-122,38,5,-3,21,39,67,31,75,-41,-98,-122,-29,6,-81,30,-86,53,10,-116,70,-35,76,-122,59,-127,-83,67,-77,21,-2, -54,48,21,25,-75,-41,-61,64,-22,-77,-93,-115,-17,51,-20,-30,-84,-72,-49,-94,29,-28,-18,9,-125,-125,28,-88,-122,-82,-47,36,23,-55,20,-65,-111,-48,-62,-113,-60,58,-76,-75,63,-4,-39,76,-85,-52,-24,-85,63,58,3,-106,-104,1,-99,-47,19,70,-109,22,-20,-110,-93,31,40,-114,-120,-86,-6,-102,-22,23,-28,25,6,-40,54,27,-74,-38,1,19,21,34,66,-68,75,55,-40,-67,46,34,13,67,-71,-40,-126,-77,-107,-43,58,-15,42,-109,-36,0,-114,-88,-61,15,-42,39,47,18,-29,-30,59,-98,-59,24,57,60,40,15,-81, 
  /* [3][0][][] */ -114,-40,-29,-127,53,-75,56,-22,44,-124,-43,-99,-43,0,-1,-35,67,-7,10,-11,20,45,41,53,8,51,55,-98,65,12,23,34,42,15,22,19,-56,-25,-122,47,-96,-65,-37,-72,19,4,59,-73,62,31,-83,-43,-58,-83,52,-83,69,53,-26,23,35,5,-29,64,-34,-89,35,-88,2,-56,55,75,11,-38,-76,-65,-33,-91,60,-57,53,-21,52,-106,28,31,-1,-17,-112,-6,64,-90,-110,1,-112,-8,-3,-30,-58,58,-99,17,-83,3,-71,-25,58,0,64,-89,63,-85,-23,-31,-83,-29,-2,-112,-105,-46,30,-105,-34,19,29,-87,-105,-3,-52, -32,-42,6,-104,-10,54,-12,51,19,-84,-78,-102,25,26,42,17,-64,-12,-85,-118,44,49,43,-97,-55,-83,65,-26,-95,-94,-64,-87,30,-107,-9,11,27,35,-41,-64,-82,-96,-44,-91,69,36,29,-97,-115,-10,51,-75,-74,-50,13,56,-2,56,-41,-6,48,-39,19,-101,31,-3,8,16,-106,21,13,-2,17,46,-118,-90,37,-100,-25,-26,63,-43,-112,-42,-114,46,-33,-83,56,17,27,35,-35,3,-58,67,14,24,-110,-103,71,-100,-117,-87,-80,34,52,-7,5,-60,42,-79,16,-87,-103,24,48,-41,71,62,19,-52,-34,-64,31,62,50,47,48, -97,-47,-63,39,-36,-53,-79,-8,-11,-107,-98,16,-4,-21,-25,-49,-69,-94,-38,75,-97,-97,-18,21,-94,29,0,-12,-101,30,-51,-71,-96,-100,-26,-32,-96,52,45,-56,22,-23,-104,78,77,11,5,-13,-10,26,-90,-43,-91,-19,15,21,-37,-14,-61,-95,-87,-55,12,82,-59,-31,-81,-45,-73,-79,-21,-46,-37,31,62,0,65,-33,-95,0,44,-47,-76,-88,26,-34,-42,-11,-62,-63,-25,1,47,-17,24,43,18,12,-25,21,56,-24,2,48,-14,41,-1,-52,-13,-83,-84,1,-43,-77,-31,9,-86,-35,51,-106,-49,-44,61,-25,-31,40,58,-72,-22, 
  /* [4][0][][] */ 42,-71,-41,59,-85,-9,-27,46,-48,-42,-106,24,13,27,-51,42,-92,-94,-85,-93,-69,-111,-99,0,-116,-62,-55,-1,29,-58,-89,-14,-83,-56,23,-83,-53,49,-67,56,76,-8,58,-18,-21,-39,61,-58,-12,-63,-35,19,-46,42,-46,8,-29,-4,14,-62,-53,22,35,35,-53,63,-16,-68,-30,92,-105,50,-111,-62,44,18,-61,6,-64,22,107,-108,-97,-25,-32,-7,78,61,-3,-26,-50,53,58,56,-57,41,-55,-72,21,-22,-18,-33,-30,-67,-38,-67,-100,-52,-58,44,28,-113,52,4,-95,45,67,57,-32,-82,-10,-1,-65,27,-36,57,60,-84,-89, -44,-103,-122,-52,-92,-101,-58,-91,32,16,-119,20,-92,40,12,-50,43,-52,22,-62,-94,-102,-52,-62,-53,61,51,-93,-87,-53,-14,-23,-20,-60,-113,17,-55,34,0,30,-34,-81,23,2,-37,60,-114,-32,-108,-55,-42,39,20,-45,-92,52,8,4,-21,-98,26,-54,-60,17,-69,-4,-68,-101,52,54,-6,43,-10,-30,-84,43,9,46,9,-68,-51,8,62,-9,-2,36,-4,-106,-33,20,-29,39,-18,-107,27,-42,-52,-85,-43,-104,70,5,0,58,-38,-5,10,-31,-54,-16,-59,-1,17,33,4,-49,-91,35,-58,-68,-57,-28,-75,-105,-73,18,12,29,74, 7,-47,44,-40,-73,30,28,-124,-42,-34,-27,49,-99,8,-82,-47,-91,-93,-29,-10,39,-16,-78,-19,32,17,-102,20,-86,48,58,13,-54,-65,12,-75,45,-89,41,2,-36,-101,64,36,-15,62,-30,-80,15,66,-62,-35,-90,13,-30,-92,-4,48,-127,-30,55,-101,-77,-76,-49,34,43,-67,-20,-91,33,39,-2,35,-13,-63,-17,-56,-11,-86,-20,-37,11,32,73,44,-101,-107,34,-34,43,-117,-8,38,-24,-24,-32,36,46,-77,-70,-72,42,-50,-44,-25,11,49,-123,28,-79,58,-83,-63,-69,-73,-24,-50,4,27,12,-52,-52,-41,42,-62,22,15,-7, 
  /* [5][0][][] */ -56,-2,-33,19,23,-9,-81,-14,-33,45,-60,63,-9,34,-57,-16,-110,4,-26,58,-65,-39,66,-126,-39,-119,-7,16,-94,72,-124,63,-7,-52,45,-8,-45,-79,53,-59,-116,-126,23,33,0,-56,-107,-85,-90,-80,-103,-102,-36,37,-68,-35,-31,-45,68,73,47,-69,22,42,-103,1,-93,46,4,7,-73,-42,-99,20,-84,-45,5,67,-54,-102,51,-101,70,-29,-1,-3,-40,-57,5,73,42,19,-35,50,-79,15,55,-71,-11,-110,43,67,-80,16,-55,-94,56,44,-1,-56,-9,58,-52,-126,-91,-100,-31,-95,15,69,-29,74,-25,-103,23,62,7,-37,69, -84,7,-100,-63,-120,27,18,64,-127,-8,-100,8,-9,53,-15,-113,31,25,-105,5,-74,0,-25,42,-81,-104,40,-42,-43,50,68,-53,40,-25,-49,27,-62,55,-125,-54,-23,61,-6,-52,16,-54,67,-109,-82,41,-62,42,38,-32,-23,66,-125,22,56,-101,-1,-38,-80,-82,-54,-100,38,21,63,43,-103,-103,-66,-125,71,-117,-75,-55,-26,-82,-9,-34,28,-18,51,67,3,46,-98,-79,-2,73,-31,-50,-7,18,-14,-19,6,13,71,-87,-94,-3,-38,-77,-22,-121,31,65,26,-38,-70,-107,-118,-61,-27,-25,-113,-70,-117,-39,-8,70,-103,15,55,-1,-40, -62,-87,-4,-87,21,-31,-127,71,-25,-89,-72,68,8,-54,-44,11,-125,-36,38,-113,-80,-72,4,-86,4,-70,-22,44,-91,61,40,4,23,29,-5,30,73,1,32,-95,24,-40,-124,-29,-119,-123,66,-103,-71,-77,60,62,-22,64,-35,19,17,-42,-106,13,-58,59,-74,10,67,14,62,-18,-108,-54,-84,18,-89,1,-56,-53,53,-6,-108,35,19,-47,18,18,-57,-28,33,51,-73,37,-124,-47,29,59,-11,-94,-117,-25,30,-70,-31,44,-11,-54,36,10,-28,62,19,22,-34,16,61,29,-84,-35,-31,50,-64,-60,-117,58,9,-103,-64,-103,-98,44,-40, 
  /* [6][0][][] */ 24,68,-39,-2,-52,-63,-82,-99,-125,-127,-90,-19,-80,-67,-17,-60,-72,61,-9,-36,-62,23,-9,9,-62,-30,74,-9,5,-65,-25,-89,50,-106,-99,21,-126,47,-60,-79,-67,-118,35,-26,-82,101,58,44,22,16,-69,87,-96,48,86,-46,-53,-81,81,81,-41,-98,-26,-19,-116,78,-41,51,-33,-30,83,81,-80,70,-72,69,104,68,-82,-45,1,-47,-74,-22,-93,-80,-16,-34,91,82,-113,-83,-7,-81,-70,-83,82,-79,6,-35,-11,-104,53,-13,21,-8,-100,-17,-32,53,-51,-17,-20,72,-16,100,-39,-83,-98,24,-10,-101,-27,40,-95,-68,-21,-23,-64, -114,-115,7,-28,-32,-85,8,-104,-110,65,-99,-17,67,-12,-70,-91,30,64,-34,-42,49,-89,6,-35,9,-80,74,-88,-8,44,56,24,-11,34,-126,-54,-93,89,-58,46,-84,-77,-19,-35,29,91,-3,10,-100,-12,31,-54,93,62,-67,-47,30,64,-111,92,31,48,-44,56,-65,19,26,-3,-62,78,18,77,54,-81,-97,19,5,-70,-4,-70,-3,-59,19,17,69,18,64,78,-2,27,10,-73,-109,0,-53,-83,-74,-47,86,97,82,-41,-16,-36,-54,-33,-33,-89,70,6,-75,-48,80,51,36,23,-92,83,30,49,-63,-62,-96,-88,63,102,5,-68,-73, 17,-16,73,-112,-66,-74,-23,-40,38,47,-119,-100,-81,-67,-43,-18,32,-31,-72,27,-23,-14,42,73,-108,24,-81,0,-121,-111,-12,-103,32,75,78,62,17,-113,52,18,-86,-118,-81,-79,57,-112,-83,-111,-37,-125,-104,-7,-64,-98,60,23,73,-35,-33,42,-3,-69,-55,68,-32,-119,-18,18,-62,-89,-69,-73,-35,-30,25,-123,-32,43,44,24,5,-82,-109,69,50,-120,74,46,-113,10,35,5,13,-60,64,-102,-58,-67,-59,67,2,-69,-102,46,-24,-125,51,46,11,-16,-64,7,54,33,-13,-68,-52,-97,-58,-79,29,13,-33,53,-15,63,20,-67,29, 
  /* [7][0][][] */ 49,-26,27,8,49,1,-101,33,-55,-74,59,-121,32,-115,-59,0,-38,71,-65,-39,-58,10,-110,-50,41,-48,-32,54,67,54,-61,-82,36,65,-27,-91,22,-48,20,-67,-60,-9,-74,-61,-110,-94,9,36,-24,1,56,-118,14,-47,-118,-79,-107,-63,-22,-104,-48,-2,26,14,-22,-53,-70,34,23,-68,-121,-45,39,13,54,-4,1,15,-47,-11,-5,-61,-70,-66,-88,-62,-33,-13,-48,10,-43,-25,-121,0,-3,43,0,43,28,-38,-43,33,36,47,-95,75,4,52,-41,31,9,45,-102,-56,-106,-5,-115,-89,21,2,-85,-98,21,-34,-21,-94,17,-28,42, 21,-45,44,-127,7,7,-59,13,-103,32,-77,-112,62,-124,-45,-110,40,-98,-37,-106,59,-93,-23,9,30,42,26,-6,47,-53,11,28,-9,-115,35,-36,-1,-9,-111,-49,-92,-71,-16,-116,-48,-85,-86,-112,-78,-22,41,-45,56,-96,-85,-39,-27,16,9,3,9,-63,-68,75,55,-123,-77,60,72,-8,-70,74,-95,40,66,-31,34,-11,-55,-79,-110,1,76,-105,-114,11,17,-15,-63,22,-35,42,32,-65,40,-24,-50,-28,9,-104,-9,-11,-4,-12,-100,-46,-107,71,-63,5,-107,-58,-107,-44,42,-95,-20,28,-49,-51,-84,-56,52,-33,-31,52,-29,71,-83, 46,-102,-39,42,-32,11,36,-71,-9,-52,72,-96,67,73,1,-110,34,-83,5,-10,-4,51,-8,-124,47,6,-88,60,34,65,-90,-12,50,-59,-21,-17,-81,-64,-29,-31,10,-32,-57,-78,55,65,-11,-36,-38,7,-45,-75,14,13,-20,-51,41,-93,-83,-85,-100,-24,-44,-53,7,49,-24,33,-43,-115,35,-23,-47,-4,62,-45,32,-92,-91,-73,-3,74,-45,-80,-4,51,54,-18,-12,43,32,-65,-39,-78,41,-11,-89,33,-66,-63,18,2,12,57,-2,-116,53,-29,71,-93,-65,53,41,-31,-99,-76,14,28,25,-87,-82,27,-17,-66,65,-17,-61,35,37, 
};
const TfArray<4, int> tensor_dimension9 = { 4, { 8,1,3,129 } };
const TfArray<8, float> quant9_scale = { 8, { 0.0012010803911834955, 0.0023352899588644505, 0.0011863067047670484, 0.0012803440913558006, 0.0013154656626284122, 0.0011975321685895324, 0.0011580523569136858, 0.0011950446059927344, } };
const TfArray<8, int> quant9_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const TfArray<4, int> tensor_dimension10 = { 4, { 1,1,50,129 } };
const TfArray<1, float> quant10_scale = { 1, { 0.0033511521760374308, } };
const TfArray<1, int> quant10_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const TfArray<4, int> tensor_dimension11 = { 4, { 1,1,50,8 } };
const TfArray<1, float> quant11_scale = { 1, { 0.011757218278944492, } };
const TfArray<1, int> quant11_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,50,1,8 } };
const TfArray<1, float> quant12_scale = { 1, { 0.011757218278944492, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,25,1,8 } };
const TfArray<1, float> quant13_scale = { 1, { 0.011757218278944492, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1,1,25,8 } };
const TfArray<1, float> quant14_scale = { 1, { 0.011757218278944492, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1,1,25,16 } };
const TfArray<1, float> quant15_scale = { 1, { 0.012254694476723671, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,25,1,16 } };
const TfArray<1, float> quant16_scale = { 1, { 0.012254694476723671, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,13,1,16 } };
const TfArray<1, float> quant17_scale = { 1, { 0.012254694476723671, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<2, int> tensor_dimension18 = { 2, { 1,208 } };
const TfArray<1, float> quant18_scale = { 1, { 0.012254694476723671, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 10 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 10,9,8 } };
const TfArray<1, int> outputs1 = { 1, { 11 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 11,2 } };
const TfArray<1, int> outputs2 = { 1, { 12 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 12 } };
const TfArray<1, int> outputs3 = { 1, { 13 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 13,3 } };
const TfArray<1, int> outputs4 = { 1, { 14 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 14,7,6 } };
const TfArray<1, int> outputs5 = { 1, { 15 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 15,5 } };
const TfArray<1, int> outputs6 = { 1, { 16 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 16 } };
const TfArray<1, int> outputs7 = { 1, { 17 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 17,4 } };
const TfArray<1, int> outputs8 = { 1, { 18 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 6464, (TfLiteIntArray*)&tensor_dimension0, 6450, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 384, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 3096, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension10, 6450, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 8016, (TfLiteIntArray*)&tensor_dimension11, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 400, (TfLiteIntArray*)&tensor_dimension13, 200, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 200, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 400, (TfLiteIntArray*)&tensor_dimension15, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 400, (TfLiteIntArray*)&tensor_dimension17, 208, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension18, 208, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant18))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs8, (TfLiteIntArray*)&outputs8, const_cast<void*>(static_cast<const void*>(&opdata8)), OP_RESHAPE, },
};

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {

  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBufferImpl(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  uint32_t align_bytes = (bytes % 16) ? 16 - (bytes % 16) : 0;

  if (current_location - (bytes + align_bytes) < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  // align to the left aligned boundary of 16 bytes
  current_location -= 15; // for alignment
  current_location += 16 - ((uintptr_t)(current_location) & 15);

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArenaImpl(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBufferImpl(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBufferImpl(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensorImpl(const struct TfLiteContext* context,
                               int tensor_idx) {

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensorImpl(const struct TfLiteContext* context,
                                       int tensor_idx) {

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

class EonMicroContext : public MicroContext {
 public:
  EonMicroContext(): MicroContext(nullptr, nullptr, nullptr) { }

  void* AllocatePersistentBuffer(size_t bytes) {
    return AllocatePersistentBufferImpl(nullptr, bytes);
  };
  TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                           int* buffer_index) {
  return RequestScratchBufferInArenaImpl(nullptr, bytes, buffer_index);
  }
  void* GetScratchBuffer(int buffer_index) {
    return GetScratchBufferImpl(nullptr, buffer_index);
  }

  TfLiteTensor* AllocateTempTfLiteTensor(int tensor_index) {
    return GetTensorImpl(nullptr, tensor_index);
  }
  void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    return;
  }
  bool IsAllTempTfLiteTensorDeallocated() {
    return true;
  }

  TfLiteEvalTensor* GetEvalTensor(int tensor_index) {
    return GetEvalTensorImpl(nullptr, tensor_index);
  }
};

} // namespace

TfLiteStatus tflite_dsp_40_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;

  EonMicroContext micro_context_;
  ctx.impl_ = static_cast<void*>(&micro_context_);
  ctx.AllocatePersistentBuffer = &AllocatePersistentBufferImpl;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArenaImpl;
  ctx.GetScratchBuffer = &GetScratchBufferImpl;
  ctx.GetTensor = &GetTensorImpl;
  ctx.GetEvalTensor = &GetEvalTensorImpl;
  ctx.tensors_size = 19;
  for (size_t i = 0; i < 19; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();

  for (size_t i = 0; i < 9; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 9; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      ResetTensors();

      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteStatus tflite_dsp_40_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(inTensorIndices[index], tensor);
  return kTfLiteOk;
}

static const int outTensorIndices[] = {
  18, 
};
TfLiteStatus tflite_dsp_40_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(outTensorIndices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_dsp_40_invoke() {
  for (size_t i = 0; i < 9; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_dsp_40_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
